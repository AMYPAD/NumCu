{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"NumCu # Numerical CUDA-based Python library built on top of CuVec . Install # pip install numcu Requirements: Python 3.7 or greater (e.g. via Anaconda or Miniconda or via python3-dev ) (optional) CUDA SDK/Toolkit (including drivers for an NVIDIA GPU) note that if the CUDA SDK/Toolkit is installed after NumCu, then NumCu must be re-installed to enable CUDA support Usage # import numcu as nc import numpy as np a = nc . zeros (( 1337 , 42 ), \"float32\" ) assert isinstance ( cu . zeros ( 1 ), np . ndarray ) b = nc . ones_like ( a ) assert np . all ( nc . div ( a , b ) == 0 )","title":"Home"},{"location":"#numcu","text":"Numerical CUDA-based Python library built on top of CuVec .","title":"NumCu"},{"location":"#install","text":"pip install numcu Requirements: Python 3.7 or greater (e.g. via Anaconda or Miniconda or via python3-dev ) (optional) CUDA SDK/Toolkit (including drivers for an NVIDIA GPU) note that if the CUDA SDK/Toolkit is installed after NumCu, then NumCu must be re-installed to enable CUDA support","title":"Install"},{"location":"#usage","text":"import numcu as nc import numpy as np a = nc . zeros (( 1337 , 42 ), \"float32\" ) assert isinstance ( cu . zeros ( 1 ), np . ndarray ) b = nc . ones_like ( a ) assert np . all ( nc . div ( a , b ) == 0 )","title":"Usage"},{"location":"contrib/","text":"Contributing # Install in \"development/editable\" mode including dev/test dependencies: git clone https://github.com/AMYPAD/NumCu && cd NumCu # `pip install -e .[dev]` won't work due to https://github.com/scikit-build/scikit-build-core/issues/114 # work-around: # 1. install dependencies (one-off) pip install toml python -c 'import toml; c=toml.load(\"pyproject.toml\") print(\"\\0\".join(c[\"build-system\"][\"requires\"] + c[\"project\"][\"dependencies\"] + c[\"project\"][\"optional-dependencies\"][\"dev\"]), end=\"\")' \\ | xargs -0 pip install -U ninja cmake # 2. delete build artefacts, (re)build & install in-place with debug info git clean -Xdf pip install --no-build-isolation --no-deps -t . -U -v . \\ -Ccmake.define.CUVEC_DEBUG = 1 -Ccmake.define.CMAKE_CXX_FLAGS = \"-Wall -Wextra -Wpedantic -Werror -Wno-missing-field-initializers -Wno-unused-parameter -Wno-cast-function-type\" git restore numcu/src # undo deletion of sources Once installed in development/editable mode, tests may be run using: pytest","title":"Contributing"},{"location":"contrib/#contributing","text":"Install in \"development/editable\" mode including dev/test dependencies: git clone https://github.com/AMYPAD/NumCu && cd NumCu # `pip install -e .[dev]` won't work due to https://github.com/scikit-build/scikit-build-core/issues/114 # work-around: # 1. install dependencies (one-off) pip install toml python -c 'import toml; c=toml.load(\"pyproject.toml\") print(\"\\0\".join(c[\"build-system\"][\"requires\"] + c[\"project\"][\"dependencies\"] + c[\"project\"][\"optional-dependencies\"][\"dev\"]), end=\"\")' \\ | xargs -0 pip install -U ninja cmake # 2. delete build artefacts, (re)build & install in-place with debug info git clean -Xdf pip install --no-build-isolation --no-deps -t . -U -v . \\ -Ccmake.define.CUVEC_DEBUG = 1 -Ccmake.define.CMAKE_CXX_FLAGS = \"-Wall -Wextra -Wpedantic -Werror -Wno-missing-field-initializers -Wno-unused-parameter -Wno-cast-function-type\" git restore numcu/src # undo deletion of sources Once installed in development/editable mode, tests may be run using: pytest","title":"Contributing"},{"location":"licence/","text":"Copyright \u00a9 Casper da Costa-Luis Citation: DOI:10.5281/zenodo.7013340 Exhibit A - Source Code Form License Notice # This Source Code Form is subject to the terms of the Mozilla Public License, v. 2.0. If a copy of the MPL was not distributed with this file, You can obtain one at https://mozilla.org/MPL/2.0 . If it is not possible or desirable to put the notice in a particular file, then you may include the notice in a location (such as a LICENCE file in a relevant directory) where a recipient would be likely to look for such a notice. You may add additional accurate notices of copyright ownership.","title":"Licence"},{"location":"licence/#exhibit-a-source-code-form-license-notice","text":"This Source Code Form is subject to the terms of the Mozilla Public License, v. 2.0. If a copy of the MPL was not distributed with this file, You can obtain one at https://mozilla.org/MPL/2.0 . If it is not possible or desirable to put the notice in a particular file, then you may include the notice in a location (such as a LICENCE file in a relevant directory) where a recipient would be likely to look for such a notice. You may add additional accurate notices of copyright ownership.","title":"Exhibit A - Source Code Form License Notice"},{"location":"ref-py/","text":"numcu._dist_ver # numcu.lib # Thin wrappers around numcu C++/CUDA module get_namespace # [view source] def get_namespace ( * xs , default = cu ) Similar to array_api_compat.get_namespace , but handles CuVec s pretending to be NumPy arrays. check_cuvec # [view source] def check_cuvec ( a , shape , dtype , xp = cu ) Asserts that CuVec a is of shape & dtype check_similar # [view source] def check_similar ( * arrays , allow_none = True ) Asserts that all arrays are CuVec s of the same shape & dtype div # [view source] def div ( numerator , divisor , default = FLOAT_MAX , output = None , dev_id = 0 , sync = True ) Elementwise output = numerator / divisor if divisor else default Args: numerator(ndarray): input. divisor(ndarray): input. default(float): value for zero-division errors. output(ndarray): pre-existing output memory. dev_id(int or bool): GPU index ( False for CPU). sync(bool): whether to cudaDeviceSynchronize() after GPU operations. mul # [view source] def mul ( a , b , output = None , dev_id = 0 , sync = True ) Elementwise output = a * b Args: a(ndarray): input. b(ndarray): input. output(ndarray): pre-existing output memory. dev_id(int or bool): GPU index ( False for CPU). sync(bool): whether to cudaDeviceSynchronize() after GPU operations. add # [view source] def add ( a , b , output = None , dev_id = 0 , sync = True ) Elementwise output = a + b Args: a(ndarray): input. b(ndarray): input. output(ndarray): pre-existing output memory. dev_id(int or bool): GPU index ( False for CPU). sync(bool): whether to cudaDeviceSynchronize() after GPU operations.","title":"Python Reference"},{"location":"ref-py/#numcu_dist_ver","text":"","title":"numcu._dist_ver"},{"location":"ref-py/#numculib","text":"Thin wrappers around numcu C++/CUDA module","title":"numcu.lib"},{"location":"ref-py/#get_namespace","text":"[view source] def get_namespace ( * xs , default = cu ) Similar to array_api_compat.get_namespace , but handles CuVec s pretending to be NumPy arrays.","title":"get_namespace"},{"location":"ref-py/#check_cuvec","text":"[view source] def check_cuvec ( a , shape , dtype , xp = cu ) Asserts that CuVec a is of shape & dtype","title":"check_cuvec"},{"location":"ref-py/#check_similar","text":"[view source] def check_similar ( * arrays , allow_none = True ) Asserts that all arrays are CuVec s of the same shape & dtype","title":"check_similar"},{"location":"ref-py/#div","text":"[view source] def div ( numerator , divisor , default = FLOAT_MAX , output = None , dev_id = 0 , sync = True ) Elementwise output = numerator / divisor if divisor else default Args: numerator(ndarray): input. divisor(ndarray): input. default(float): value for zero-division errors. output(ndarray): pre-existing output memory. dev_id(int or bool): GPU index ( False for CPU). sync(bool): whether to cudaDeviceSynchronize() after GPU operations.","title":"div"},{"location":"ref-py/#mul","text":"[view source] def mul ( a , b , output = None , dev_id = 0 , sync = True ) Elementwise output = a * b Args: a(ndarray): input. b(ndarray): input. output(ndarray): pre-existing output memory. dev_id(int or bool): GPU index ( False for CPU). sync(bool): whether to cudaDeviceSynchronize() after GPU operations.","title":"mul"},{"location":"ref-py/#add","text":"[view source] def add ( a , b , output = None , dev_id = 0 , sync = True ) Elementwise output = a + b Args: a(ndarray): input. b(ndarray): input. output(ndarray): pre-existing output memory. dev_id(int or bool): GPU index ( False for CPU). sync(bool): whether to cudaDeviceSynchronize() after GPU operations.","title":"add"}]}